---
title: "Machine Learning Application in Qualified Self Movement"
output: html_document
---


### Executive Summary

This project aims to predict the manner in which the quantified self movement enthusiasts exercise by using data collected from accelerometers on the belt, forearm, arm and dumbell of 6 participants. The quantified self movement is a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. They use devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. The 6 participants were asked to perform barbell lifts correctly and incorrectly in 5 different ways and data was collected from accelerometers on the belt, forearm, arm, and dumbell of the participants. 

### Loading Dataset

We download datafiles if they don't exist and then load data files into training and testing datasets.

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache=TRUE)
```

```{r}
if( !file.exists("training.csv") ) {
       fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
        download.file(fileUrl, destfile="training.csv", method="curl") 
}

if( !file.exists("testing.csv")){
         fileUrl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
         download.file(fileUrl, destfile="testing.csv", method="curl") 
}

training0 <- read.csv("training.csv", na.strings=c("","NA"))
testing0  <- read.csv("testing.csv", na.strings=c("","NA"))
```

This project is to predict the *class* variable which represents the five categories of exercise manners of the participants as follows:
* Class A exactly according to the specification
* Class B throwing the elbows to the front 
* Class C lifting the dumbbell only halfway
* Class D lowering the dumbbell only halfway
* Class E throwing the hips to the front

### Data Processing

The training set has `r nrow(training0)` observations and `r ncol(training0)` variables including "classe" variable representing the manner of the exercise for us to predict against. 


First, we clean the dataset dropping variables not useful for prediction.

1 Drop variables *X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp, new_window, num_window* because they do not help predict the *classe*;

2 Drop variables with all missing values;

3 Drop near zero variance predictors that have one unique value or that have both of the following characteristics: they have few unique values relative to the number of samples and the ratio of the frequency of the most common value to the frequency of the second most common value is large.

```{r}
library(dplyr)
library(caret)
#remove names and time variables
var_rm <- c("X","user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
training <- select(training0, -one_of(var_rm))
testing  <- select(testing0,-one_of(var_rm))

#remove variables with more than 90% values missing  
idx <- which(colSums(is.na(training))/nrow(training) > .9)
training <- training[,-idx]
testing  <- testing[,-idx]
#remove near zero variance predictors
nsv <- nearZeroVar(training)
if( length(nsv) > 0 ) {
     training <- training[,-nsv]
     testing  <- testing[,-nsv]
     }
```

Next, we split the training dataset into two subsets for later cross validation test with 70% data for model training and 30% for validation use.

```{r}
inTrain        <- createDataPartition(y=training$classe, p=.7, list=F)
training_sub   <- training[inTrain,]
validating_sub <- training[-inTrain,]
dim(training_sub)
dim(validating_sub)
```

We then check the correlation of the predictive variables and use PCA (principal component analysis) to transform the data to a smaller sub-space where the new variables are uncorrelated with one another.

```{r}
library(caret)
#Check correlation
corIdx <- findCorrelation(cor(training_sub[,-53]), cutoff= .9)

#PCA preprocess
preProc   <- preProcess(training_sub[,-53], method="pca", thresh=.9)
trainPC <- predict(preProc,training_sub[,-53])
validPC <- predict(preProc,validating_sub[,-53])
```

### Model Fitting and Cross Validation

We use random forest approach to train model on the training subset. Cross validation method is set in the "trainControl()" parameter.

```{r}
set.seed(12345)
modelFit <- train(training_sub$classe ~ ., method = "rf", data = trainPC, trControl = trainControl(method = "cv", number = 4), importance = TRUE)
```

Next, we apply the fitted model to the cross validation subset and using *confusionMatrix* function to see how well the model perform.

```{r}
confMat    <- confusionMatrix(validating_sub$classe, predict(modelFit, validPC))
mod_accuracy <-  confMat$overall["Accuracy"]
error <- 1 - mod_accuracy
```

The estimated model accuracy is `r mod_accuracy` and the estimated out of sample error is  `r error`.

### Prediction Results

We apply the model to the testing data set and predict the manner in which the paticipate exercise.

```{r}
testPC   <- predict(preProc,testing[,-53])
testPred <- predict(modelFit, testPC) 
testPred
```

